{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495f667b",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Modifica e caricamento del dataset.\\\n",
    "Il dataset usato in questo caso è il dataset [COVIDx CXR-4](https://www.kaggle.com/datasets/andyczhao/covidx-cxr2).\\\n",
    "Esso deve esser messo dentro la cartella 'datasets' al di fuori di questa cartella.\n",
    "\n",
    "Questo notebook serve a modificare il dataset e a creare una cache contenente le immagini già pre-elaborate.\\\n",
    "Queste sono le azioni fatte ad ogni immagine:\n",
    "- Caricamento dalla cartella del dataset\n",
    "- Rimozione dei canali di colore \\(alcune immagini hanno per esempio delle scritte rosse\\); quindi ogni immagine è in scala di grigio.\n",
    "- Salvataggio in float\n",
    "\n",
    "Ogni immagine poi è accoppiata ad un valore 0 o 1 in base alla propria classe di appartenenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3feafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.api.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Define the dataset and cache paths\n",
    "directory = '../../datasets/covid_cxr'\n",
    "cache = f\"{directory}_cache.npy\"\n",
    "types = ['train', 'val', 'test']\n",
    "size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95659e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the names of the images in one pandas\n",
    "all_files = []\n",
    "for t in types:\n",
    "    df = pd.read_csv(f\"{directory}/{t}.txt\", delimiter=' ', header=None)\n",
    "    df[1] = df[1].apply(lambda x: f\"{directory}/{t}/{x}\")\n",
    "    all_files.append(df)\n",
    "\n",
    "df = pd.concat(all_files)\n",
    "df.columns = ['id', 'filename', 'class', 'source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77718c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84818/84818 [06:45<00:00, 209.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transform all the images into a numpy array\n",
    "images = df['filename']\n",
    "np_images = np.zeros((len(images), *size, 1), dtype=np.uint8)\n",
    "for i, img_name in enumerate(tqdm(images)):\n",
    "    img = load_img(img_name, target_size=size, color_mode='grayscale')\n",
    "    img = img_to_array(img, dtype=\"uint8\")\n",
    "    np_images[i] = img.reshape((*size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2aee4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the classes to a numpy array\n",
    "predictions = np.array(pd.factorize(df['class'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_tot = len(all_files[0])\n",
    "val_tot = train_tot + len(all_files[1])\n",
    "test_tot = val_tot + len(all_files[2])\n",
    "\n",
    "# Create a dictionary to store the dataset\n",
    "dataset = {}\n",
    "dataset['train'] = (np_images[:train_tot], predictions[:train_tot])\n",
    "dataset['val'] = (np_images[train_tot:val_tot], predictions[train_tot:val_tot])\n",
    "dataset['test'] = (np_images[val_tot:test_tot], predictions[val_tot:test_tot])\n",
    "\n",
    "# Save the dataset to a cache file\n",
    "np.save(cache, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
