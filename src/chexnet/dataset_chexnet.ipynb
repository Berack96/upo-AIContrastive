{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheXNet\n",
    "Uso della CheXNet per migliorare gli embedding e le predizioni.\\\n",
    "Per prima cosa carico la CheXNet dall'architettura DenseNet121 e dai pesi scaricati nella apposita directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621e5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras import models, applications\n",
    "from keras.api.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "root = '../..'\n",
    "dataset_path = f\"{root}/datasets/covid_cxr\"\n",
    "chexnet_path = f\"{root}/models/CheXNet.keras\"\n",
    "batch = 32\n",
    "size = (224, 224)\n",
    "\n",
    "if not os.path.exists(chexnet_path):\n",
    "    base = applications.densenet.DenseNet121(weights=None, include_top=True, input_shape=(224,224,3), classes=14)\n",
    "    base.load_weights(f\"{root}/models/weight_only/CheXNet.h5\")\n",
    "    base.save(chexnet_path)\n",
    "\n",
    "base = models.load_model(chexnet_path, compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto carico la CheXNet e predico tutti gli embedding per le immagini.\\\n",
    "Per fare questo devo quindi rimuovere l'ultimo layer per la classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f85c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheXnet = models.Model(inputs=base.input, outputs=base.layers[-2].output)\n",
    "for layer in cheXnet.layers: layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e82e3",
   "metadata": {},
   "source": [
    "In questo punto carico il dataset e lo trasformo in embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6d8616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84818/84818 [11:11<00:00, 126.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all the names of the images in one pandas\n",
    "all_files = []\n",
    "for t in ['train', 'val', 'test']:\n",
    "    df = pd.read_csv(f\"{dataset_path}/{t}.txt\", delimiter=' ', header=None)\n",
    "    df[1] = df[1].apply(lambda x: f\"{dataset_path}/{t}/{x}\")\n",
    "    all_files.append(df)\n",
    "df = pd.concat(all_files)\n",
    "df.columns = ['id', 'filename', 'class', 'source']\n",
    "\n",
    "# Convert the classes to a numpy array\n",
    "predictions = np.array(pd.factorize(df['class'])[0])\n",
    "\n",
    "# Create the embeddings for the images\n",
    "images = df['filename']\n",
    "embeddings = np.zeros((len(images), 1024), dtype=\"float32\")\n",
    "img_batch = []\n",
    "for i, img_name in enumerate(tqdm(images)):\n",
    "    img = load_img(img_name, target_size=size, color_mode='rgb')\n",
    "    img = img_to_array(img)\n",
    "    img_batch.append(img)\n",
    "    if len(img_batch) == batch or i == len(images) - 1:\n",
    "        img_batch = np.array(img_batch)\n",
    "        batch_embeddings = cheXnet.predict(img_batch, verbose=0)\n",
    "        embeddings[i - len(img_batch) + 1:i + 1] = batch_embeddings\n",
    "        img_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2b058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 67863, Validation: 8473, Test: 8482\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_tot = len(all_files[0])\n",
    "val_tot = train_tot + len(all_files[1])\n",
    "test_tot = val_tot + len(all_files[2])\n",
    "print(f\"Train: {train_tot}, Validation: {val_tot - train_tot}, Test: {test_tot - val_tot}\")\n",
    "\n",
    "# Save the embeddings and predictions to a numpy file\n",
    "np.savez(\n",
    "    f\"{dataset_path}_embeddings.npz\",\n",
    "    x_train=embeddings[:train_tot],\n",
    "    y_train=predictions[:train_tot],\n",
    "    x_val=embeddings[train_tot:val_tot],\n",
    "    y_val=predictions[train_tot:val_tot],\n",
    "    x_test=embeddings[val_tot:test_tot],\n",
    "    y_test=predictions[val_tot:test_tot],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
