{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzione\n",
    "In questo file troviamo un modello di rete neurale per la classificazione del dataset COVID-CXR4.\\\n",
    "IL dataset è stato scaricato da [Kaggle](https://www.kaggle.com/datasets/andyczhao/covidx-cxr2) e messo dentro la cartella datasets \\(questa cartella è ignorata da git perchè il dataset è grosso)\\\n",
    "I modelli salvati si possono trovare sotto la cartella [models](models) in modo da poterli usare senza rifare l'addestramento.\n",
    "\n",
    "Questo *interactive pyhon notebook* è suddiviso in 3 parti principali:\n",
    "- **Dataset**: in cui viene caricato, modificato e salvato in una cache l'intero dataset di immagini.\n",
    "- **Modello**: in cui vengono creati e addestrati l'autoencoder e il classificatore.\n",
    "- **Contrastive Learning**: in cui viene applicata la tecnica di contrastive learning per migliorare gli embedding da passare al classificatore.\n",
    "\n",
    "Ogni parte del notebook contiene anche dei grafici e immagini per mostrare come i vari modelli si comportano.\n",
    "\n",
    "In questa prima parte vengono importati le varie librerie usate e vengono create le variabili globali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras import layers, models, optimizers\n",
    "from keras.api.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "models_dir = '../models'\n",
    "datasets_dir = '../datasets'\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(datasets_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Modifica e caricamento del dataset.\n",
    "Il dataset usato in questo caso è il dataset [COVIDx CXR-4](https://www.kaggle.com/datasets/andyczhao/covidx-cxr2).\n",
    "\n",
    "Le modifiche apportate sono:\n",
    "- Rimozione dei canali di colore \\(alcune immagini hanno per esempio delle scritte rosse\\); quindi ogni immagine è in scala di grigio.\n",
    "- Ridimensionamento a 224x224 \\(molte immagini sono 1024x1024 ma ci sono anche di dimensioni diverse\\)\n",
    "\n",
    "Le immagini importate sono sottoforma di array di numpy a 8bit che poi vengono salvate in un file cache (~4GB).\\\n",
    "Il primo blocco di codice dichiara delle funzioni utili per la modifica del dataset. La funzione `covid_cxr_data` è quella responsabile per il caricamento dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(file) -> dict:\n",
    "    try:\n",
    "        return dict(np.load(file, allow_pickle=True).item())\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def images_to_numpy(images: pd.Series, size: tuple[int, int]):\n",
    "    np_images = np.zeros((len(images), *size, 1), dtype=np.uint8)\n",
    "    for i, img_name in enumerate(tqdm(images)):\n",
    "        img = load_img(img_name, target_size=size, color_mode='grayscale')\n",
    "        np_images[i] = img_to_array(img, dtype=np.uint8).reshape((*size, 1))\n",
    "    return np_images\n",
    "\n",
    "def classes_to_numpy(classes: pd.Series):\n",
    "    return np.array(pd.factorize(classes)[0])\n",
    "\n",
    "def covid_cxr_data(size:tuple[int, int]=(256, 256)):\n",
    "    directory = f\"{datasets_dir}/covid_cxr\"\n",
    "    cache = f\"{directory}/cache_{size[0]}x{size[1]}.npy\"\n",
    "    dataset = load_cache(cache)\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        types = ['train', 'val', 'test']\n",
    "        all_files = []\n",
    "        for t in types:\n",
    "            df = pd.read_csv(f\"{directory}/{t}.txt\", delimiter=' ', header=None)\n",
    "            df[1] = df[1].apply(lambda x: f\"{directory}/{t}/{x}\")\n",
    "            all_files.append(df)\n",
    "\n",
    "        df = pd.concat(all_files)\n",
    "        df.columns = ['id', 'filename', 'class', 'source']\n",
    "        images = images_to_numpy(df['filename'], size)\n",
    "        predictions = classes_to_numpy(df['class'])\n",
    "\n",
    "        train_tot = len(all_files[0])\n",
    "        val_tot = train_tot + len(all_files[1])\n",
    "        test_tot = val_tot + len(all_files[2])\n",
    "\n",
    "        dataset['train'] = (images[:train_tot], predictions[:train_tot])\n",
    "        dataset['val'] = (images[train_tot:val_tot], predictions[train_tot:val_tot])\n",
    "        dataset['test'] = (images[val_tot:test_tot], predictions[val_tot:test_tot])\n",
    "\n",
    "        np.save(cache, dataset)\n",
    "\n",
    "    x_train, y_train = dataset['train'][0], dataset['train'][1]\n",
    "    x_val, y_val = dataset['val'][0], dataset['val'][1]\n",
    "    x_test, y_test = dataset['test'][0], dataset['test'][1]\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "def data_generator(x, y, batch_size=32):\n",
    "    num_samples = x.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    while True:\n",
    "        np.random.shuffle(indices)  # Mescola gli indici all'inizio di ogni epoca\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            batch = image_int_to_float(x[batch_indices])\n",
    "            #batch_val = y[batch_indices].reshape(-1, 1)\n",
    "            yield batch, batch\n",
    "\n",
    "def image_int_to_float(image:np.ndarray):\n",
    "    return image.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito carichiamo il dataset usando le funzioni dichiarate precedentemente e mostriamo quanti dati sono stati caricati per ogni tipologia \\(training, validation, test\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (224, 224)\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = covid_cxr_data(shape)\n",
    "total_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Train: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation: {x_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test: {x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito viene mostrato quante classi ci sono e come sono distribuite all'interno del dataset.\\\n",
    "Come si può notare il training set è sbilanciato verso una classe e questo non aiuta per l'addestramento del classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples per class for each dataset\n",
    "train_counts = np.bincount(y_train)\n",
    "val_counts = np.bincount(y_val)\n",
    "test_counts = np.bincount(y_test)\n",
    "\n",
    "# Plot the counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_labels = range(total_classes)\n",
    "plt.bar(x_labels, train_counts, width=0.2, label='Train', align='center')\n",
    "plt.bar([x + 0.25 for x in x_labels], val_counts, width=0.2, label='Validation', align='center')\n",
    "plt.bar([x + 0.5 for x in x_labels], test_counts, width=0.2, label='Test', align='center')\n",
    "plt.xticks(x_labels, [f\"Class {i}\" for i in x_labels])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Number of Samples per Class in Each Dataset')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modello\n",
    "In questa sezione vediamo i modelli per l'autoencoding e per la classificazione.\\\n",
    "Per prima cosa definiamo le variabili in cui troviamo i modelli e gli eventuali parametri di essi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = 256\n",
    "paths = {\n",
    "    'encoder': f\"{models_dir}/encoder_{shape[0]}x{shape[1]}.keras\",\n",
    "    'autoencoder': f\"{models_dir}/autoencoder_{shape[0]}x{shape[1]}.keras\",\n",
    "    'classifier': f\"{models_dir}/classifier_{shape[0]}x{shape[1]}.keras\",\n",
    "    'contrastive': f\"{models_dir}/contrastive_{shape[0]}x{shape[1]}.keras\",\n",
    "    'history_autoencoder': f\"{models_dir}/history_auto_{shape[0]}x{shape[1]}.npy\",\n",
    "    'history_classifier': f\"{models_dir}/history_clf_{shape[0]}x{shape[1]}.npy\",\n",
    "    'history_contrastive': f\"{models_dir}/history_con_{shape[0]}x{shape[1]}.npy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "Il primo modello creato è l'autoencoder e usa gli stessi principi delle CNN per creare una rappresentazione compatta delle immagini. Infatti il modello è composto da dei Convolutional Layer che, riducono la dimensione spaziale per aumentare la dimensionde dei filtri.\\\n",
    "L'encoder ha inoltre dei layer di BatchNormalization.\n",
    "\n",
    "Questo modello è quello più lungo da addestrare solamente perchè ha abbastanza parametri e il dataset, essendo grande, non ci sta in memoria.\\\n",
    "Per queste ragioni la batch è abbastanza piccola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    encoder = models.load_model(paths['encoder'])\n",
    "    autoencoder = models.load_model(paths['autoencoder'])\n",
    "\n",
    "    enc_space = encoder.output_shape[1]\n",
    "    if enc_space != latent_space:\n",
    "        print(f\"Encoder latent space mismatch: {enc_space} != {latent_space}\")\n",
    "    latent_space = enc_space\n",
    "\n",
    "except Exception as e:\n",
    "    in_encoder = layers.Input(shape=(*shape, 1))\n",
    "    x = layers.BatchNormalization()(in_encoder)\n",
    "    x = layers.Conv2D(32, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    before_flatten = x.shape[1:]\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    flatten = x.shape[1]\n",
    "    latent = layers.Dense(latent_space, activation='sigmoid')(x)\n",
    "    encoder = models.Model(in_encoder, latent, name='encoder')\n",
    "\n",
    "    in_decoder = layers.Input(shape=(latent_space,))\n",
    "    x = layers.Dense(flatten, activation='relu')(in_decoder)\n",
    "    x = layers.Reshape(before_flatten)(x)\n",
    "    x = layers.Conv2DTranspose(256, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, padding='same', strides=2, activation='relu')(x)\n",
    "    out_decoder = layers.Conv2DTranspose(1, 3, padding='same', activation='sigmoid')(x)\n",
    "    decoder = models.Model(in_decoder, out_decoder, name='decoder')\n",
    "\n",
    "    in_autoencoder = layers.Input(shape=(*shape, 1))\n",
    "    encoder_out = encoder(in_autoencoder)\n",
    "    decoder_out = decoder(encoder_out)\n",
    "    autoencoder = models.Model(in_autoencoder, decoder_out, name='autoencoder')\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(), loss='mse')\n",
    "\n",
    "    batch = 32\n",
    "    epochs = 4\n",
    "    batch_steps = len(x_train) // batch\n",
    "    batch_val_steps = len(x_val) // batch\n",
    "    gen_train = data_generator(x_train, y_train, batch)\n",
    "    gen_val = data_generator(x_val, y_val, batch)\n",
    "\n",
    "    history_auto = autoencoder.fit(gen_train, validation_data=gen_val,\n",
    "                                   epochs=epochs, steps_per_epoch=batch_steps, validation_steps=batch_val_steps)\n",
    "\n",
    "    autoencoder.save(paths['autoencoder'])\n",
    "    encoder.save(paths['encoder'])\n",
    "    np.save(paths['history_autoencoder'], history_auto.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificatore\n",
    "Il classificatore è un modello semplice con 2 layer densi e un layer finale per la classificazione con la softmax.\\\n",
    "Essendo i dati molto più piccoli le batch possono essere alte e si possono avere molte più epoche per far imparare.\n",
    "\n",
    "Purtroppo essendo il dataset molto sbilanciato verso una classe l'addestramento viene influenzato negativamente se non si fanno delle correzioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    classifier = models.load_model(paths['classifier'])\n",
    "\n",
    "except Exception:\n",
    "    in_classifier = layers.Input(shape=(latent_space,))\n",
    "    x = layers.Dense(64, activation='relu')(in_classifier)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    out_classifier = layers.Dense(total_classes, activation='softmax')(x)\n",
    "    classifier = models.Model(in_classifier, out_classifier, name='classifier')\n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    batch = 1024\n",
    "    epochs = 100\n",
    "    x_train_class = encoder.predict(x_train, verbose=0)\n",
    "    x_val_class = encoder.predict(x_val, verbose=0)\n",
    "\n",
    "    history_class = classifier.fit(x_train_class, y_train, validation_data=(x_val_class, y_val),\n",
    "                                   epochs=epochs, batch_size=batch)\n",
    "\n",
    "    classifier.save(paths['classifier'])\n",
    "    np.save(paths['history_classifier'], history_class.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risultati\n",
    "Di seguito i risultati dell'addestramento se è stato fatto, altrimenti vengono mostrati solo delle predizioni di alcuni dati di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    np.load(paths['history_autoencoder'], allow_pickle=True).item(),\n",
    "    np.load(paths['history_classifier'], allow_pickle=True).item()\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, h in enumerate(history):\n",
    "    metric = list(h.keys())[0]\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(h[metric], label=f'Training {metric}')\n",
    "    plt.plot(h[f'val_{metric}'], label=f'Validation {metric}')\n",
    "    plt.title(f'Model {metric}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose N random images from the test set\n",
    "total = 10\n",
    "indices = np.random.choice(len(x_test), total, replace=False)\n",
    "orig_img = image_int_to_float(x_test[indices])\n",
    "orig_classes = y_test[indices]\n",
    "pred_img = autoencoder.predict(orig_img, verbose=0)\n",
    "pred_classes = classifier.predict(encoder.predict(orig_img, verbose=0), verbose=0)\n",
    "\n",
    "# Plot the original and predicted images\n",
    "plt.figure(figsize=(15, 3.5))\n",
    "for i, _ in enumerate(indices):\n",
    "    ax = plt.subplot(2, total, i + 1)\n",
    "    plt.imshow(orig_img[i], cmap='gray')\n",
    "    plt.title(f\"Original: {orig_classes[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    pred = np.argmax(pred_classes[i])\n",
    "    correct = pred == orig_classes[i]\n",
    "\n",
    "    ax = plt.subplot(2, total, i + total + 1)\n",
    "    plt.imshow(pred_img[i], cmap='gray')\n",
    "    plt.title(f\"Pred: {pred_classes[i][pred]:.2f}\", color='green' if correct else 'red')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
